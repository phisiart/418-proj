---
title: "OpenGL for GPGPU"
bg: black
color: white
fa-icon: paint-brush
---

## How to Perform GPGPU Computation in OpenGL?

The key challenge of this project is how to use OpenGL to perform general tensor computation. OpenGL is originally designed for rendering.

Although OpenGL 4.3 introduced the **compute shader**, which is similar to CUDA kernels, we are targeting OpenGL 3, which matches WebGL 2. As a result, we must still utilize the traditional rendering pipeline.

<br/>
<center>
<img src="img/opengl.png" alt="opengl" style="width: 600px;"/>
</center>
<br/>
<center>
Figure 2. Mapping from Various Concepts to OpenGL
</center>
<br/>

The core features of OpenGL that we are utilizing are **fragment shaders** and **textures**.

### Fragment Shaders

A fragment shader is a per-pixel computation kernel. Within the fragment shader, the programmer writes one and only one pixel in the output frame. If we map our output tensor onto the 2D screen, then we can compute one element in each instance of a kernel.

This is the mechanism we use to achieve **data parallelism**. The GPU executes instances of the kernel in parallel.

### Textures

A texture, roughly speaking, is how OpenGL stores an image. Normally it is used to attach an image to a surface (e.g. a wall) that we want to draw. Here we utilize textures to store our input and output tensors. We can program our fragment shader to take `uniform` values representing textures, and apply the `texelFetch` function to perform random read on them.

Note that `uniform` values are immutable, which means we cannot attach our output texture to a `uniform` and randomly write to it. We still cannot bypass the limitation that we can only assign to one output pixel in the kernel.

OpenGL is set up to render to a window by default, but we want to compute a tensor. Therefore, we create a framebuffer and attach a texture to it. Then, after rendering finishes, the output tensor is stored in the specified texture, and we can retrieve the data from it.
